# Computer Vision Nanodegree

by [Udacity](https://www.udacity.com/)<br/>
## Introduction
This program is designed to give you The cuting-edge Computer Vision theroy and programming techniques to apply them in various Real-World application and the skills you need to pursue a new role to your career as a Computer Vision Engineer.  


## Overview
  - This Nanodegree was given as a scholarship from [NTL](http://techleaders.eg/)
  - This Repository contains my projects for the [Computer Vision Nanodegree](https://www.udacity.com/course/computer-vision-nanodegree--nd891)

## Content
  1. [**Facial Keypoints Detection**](https://github.com/MohamedAskar/Computer-Vision-Nanodegree/tree/master/1.%20Facial%20Keypoints%20Detector)<br/>
  
  
  - In this project, We try to build a model using Haar Cascading algorithm and a Convolutional Neural Network (CNN) that can predict Facial Keypoints. The model takes an image with any number of faces on it and it predicts for each face the 68 distingusing keypoint.<br/>
  
  
  ![](https://user-images.githubusercontent.com/47199425/85956298-671d8c00-b985-11ea-9449-2be79b15d86a.png)<br/>
  ![](https://user-images.githubusercontent.com/47199425/85956462-5d485880-b986-11ea-9adb-b70bfba06842.png) ![](https://user-images.githubusercontent.com/47199425/85956358-a2b85600-b985-11ea-8d8a-1df1abfd14c3.png) 

  2. [**Image Captioning**](https://github.com/MohamedAskar/Computer-Vision-Nanodegree/tree/master/2.%20Image%20Captioning)<br/>
  
  
  - Using Long short-term memory (LSTM) and Convolutional Neural Network (CNN), we built a model trained on Microsoft Common Objects in Context dataset (COCO) which can extract features from an input image using CNN then convert this features into caption using LSTM.<br/>
  
  
 ![](https://user-images.githubusercontent.com/47199425/85957480-f333b180-b98d-11ea-9001-ef134b40baf1.png)  ![](https://user-images.githubusercontent.com/47199425/85957453-deefb480-b98d-11ea-93d3-008a8f957ebe.png) 



  3. [**SLAM**](https://github.com/MohamedAskar/Computer-Vision-Nanodegree/tree/master/3.%20SLAM)<br/>
  
  
  
  - In this project, we implement Simultaneous Localization and Mapping (SLAM) for a 2D world. We gather data from sensors and motion using simulated robot to create a map of an environment. SLAM gives us a way to track the location of a robot in the world in real-time and identify the locations of landmarks surround it.<br/>
  
  
  `Last pose:  (5.954003287856551, 12.454091677416208)`
![](https://user-images.githubusercontent.com/47199425/85957654-638f0280-b98f-11ea-8560-4428a0317e56.png)

## Authors
  - [**Mohamed Askar**](https://github.com/MohamedAskar)
  

  

